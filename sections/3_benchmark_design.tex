\section{Dynamic-MSV-Bench and 4D Decoupled Methodology}
\label{sec:benchmark}

We propose the \textbf{Dynamic-MSV-Bench}, a meticulously controlled stress-test dataset designed specifically to expose the structural blind spots of current video generation models. Unlike generic quality benchmarks that rely on massive, uncurated prompt pools, our benchmark consists of exactly 1,000 highly targeted multi-shot scenarios. This scale is optimal for exposing the "Double-Kill" dilemma while remaining computationally feasible for our rigorous frame-by-frame 4D evaluation pipeline. Table~\ref{tab:taxonomy} details our comprehensive taxonomy, dividing the 1,000 scenarios equally into Track S and Track M.

\begin{table*}[h!]
\centering
\caption{The Comprehensive Taxonomy of Dynamic-MSV-Bench (1,000 Scenarios). Each track features 500 prompts distributed across 4 sub-categories to test extreme edge cases, preventing models from exploiting uniform continuity.}
\label{tab:taxonomy}
\resizebox{0.95\textwidth}{!}{
\begin{tabular}{llcll}
\toprule
\textbf{Track} & \textbf{Sub-category} & \textbf{Count} & \textbf{Objective} & \textbf{Target Vulnerability} \\
\midrule
\multirow{4}{*}{\textbf{Track S (Leap)}} & Spatial & 125 & Shift to entirely different physical locations (e.g., Jungle $\rightarrow$ Space) & Identity Amnesia \\
& Temporal & 125 & Shift across different eras (e.g., Medieval $\rightarrow$ Cyberpunk) & Identity Amnesia \\
& Atmosphere & 125 & Extreme weather/environmental changes in the same location & Static Trap \\
& Scale & 125 & Microscopic to macroscopic perspective shifts & Identity Amnesia \\
\midrule
\multirow{4}{*}{\textbf{Track M (Motion)}} & Translational & 125 & X/Y axis camera panning without background breakdown & Static Trap \\
& Depth & 125 & Z axis zoom in/out maintaining subject identity & Identity Amnesia \\
& Tracking/Orbit & 125 & Complex 360-degree rotational rendering & Background Hallucination \\
& Compound & 125 & Mixed instructions (e.g., Pan Right + Zoom In) & Context Bleeding \\
\bottomrule
\end{tabular}
}
\end{table*}

\subsection{Evaluation Scenarios: Track S and Track M}
As illustrated in Figure~\ref{fig:sets_comparison}, our evaluation framework categorizes generation scenarios into two conceptually orthogonal extremes to stress-test narrative robustness and spatial coherence.

\begin{figure*}[t]
    \centering
    \includegraphics[width=\textwidth]{figures/images/fig_AB.jpg}
    \caption{Conceptual comparison of our two evaluation tracks. (Left) \textbf{Track S: Semantic Leap} tests narrative diversity, requiring radical environment changes while preserving the subject. (Right) \textbf{Track M: Motion Continuity} evaluates spatial integrity, where the background must remain consistent while the camera executes specific motions.}
    \label{fig:sets_comparison}
\end{figure*}

\subsection{Formulation of 4D Decoupled Metrics}
To diagnose generative failures accurately, we introduce four strictly decoupled metrics designed with robust mathematical penalty mechanisms to prevent error propagation and metric exploitation.

\noindent\textbf{1. Subject Consistency ($\mathcal{C}_{subj}$).} We measure the semantic identity preservation of the core subject using DINOv2 embeddings. The subjects are localized using Grounding DINO to prevent background bias. Crucially, we enforce a strict \textbf{Error Propagation Penalty}: if the masking model fails to detect the subject due to severe 'Identity Amnesia' or catastrophic morphing into the background, the frame is immediately assigned a hard consistency score of $0.0$. This ensures that catastrophic generation failures are actively penalized rather than ignored.

\noindent\textbf{2. Background Diversity ($\mathcal{D}_{bg}$).} To formally identify the \textit{Static Trap}, we measure the variance of the background environment embeddings. $\mathcal{D}_{bg}$ is calculated as the mean perceptual distance from the average background embedding. A low score in Track S definitively confirms the model has failed to execute the semantic leap.

\noindent\textbf{3. Cut-Transition Sharpness ($\mathcal{S}_{cut}$).} Traditional metrics assume a fixed cut time ($t_{cut}$), which is unrealistic as generative models often transition gradually or at unpredictable frames. To solve this, we introduce a \textbf{Dynamic Sliding Window Peak Prominence} algorithm. We calculate the LPIPS distance across all adjacent frames within a window $W$ and define sharpness as the peak distance normalized by the surrounding mean:
$$\mathcal{S}_{cut} = 1 - \frac{1}{\frac{\max_{t \in W} \text{LPIPS}(f_t, f_{t+1})}{\text{mean}(\text{LPIPS}) + \epsilon} + 1}$$
This mathematically differentiates a sharp, deliberate cinematic cut from a slow, blurry fade.

\noindent\textbf{4. Diagonal Semantic Alignment (DSA).} Traditional CLIP scores suffer from a "Global Similarity Paradox," failing to capture specific instruction adherence. We solve this by applying a column-wise softmax to the shot-prompt similarity matrix $M$:
$$P_{i,j} = \frac{\exp(\tau \cdot M_{i,j})}{\sum_{k=1}^{K} \exp(\tau \cdot M_{k,j})}, \quad DSA = \max \left( 0, \frac{\frac{1}{K}\sum_{i=1}^{K} P_{i,i} - \frac{1}{K}}{1 - \frac{1}{K}} \right)$$
\textbf{Hyperparameter Robustness:} The temperature $\tau$ is not an arbitrary hyperparameter, but the learned logit scale inherent to the pre-trained CLIP model (typically $\sim 100.0$). As detailed in our Appendix Ablation Studies, varying $\tau \in \{0.1, 1.0, 10.0, 100.0\}$ strictly preserves the Spearman rank correlation among evaluated models. DSA consistently exposes the Static Trap ($DSA \approx 0$) regardless of the scale, proving it is a structurally robust evaluator of multi-shot independence.

\begin{figure*}[t]
    \centering
    \includegraphics[width=\textwidth]{figures/dsa_heatmaps_phd.pdf}
    \caption{Diagonal Semantic Alignment (DSA) Heatmaps. (A) Models in the \textbf{Static Trap} exhibit a uniform probability distribution across prompts. (B) Models suffering from \textbf{Context Bleeding} exhibit noisy diagonal alignment. (C) An \textbf{Ideal Decoupled Model} achieves sharp, precise diagonal alignment, proving independent shot execution.}
    \label{fig:dsa_heatmaps}
\end{figure*}