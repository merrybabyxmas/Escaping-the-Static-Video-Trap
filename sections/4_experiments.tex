\section{Experiments}
\label{sec:experiments}

Our evaluation on the \textbf{DIAL} benchmark reveals systematic failures in current video generation architectures. To properly diagnose these failures, we categorized the evaluated baselines into two distinct groups: \textbf{Group 1: Foundation T2V Models} and \textbf{Group 2: Specialized T2MSV Frameworks}.

\begin{figure*}[t!]
    \centering
    \begin{subfigure}{0.48\linewidth}
        \includegraphics[width=\linewidth]{figures/bar_chart_set_a.pdf}
        \caption{Track S: Semantic Leap}
    \end{subfigure}\hfill
    \begin{subfigure}{0.48\linewidth}
        \includegraphics[width=\linewidth]{figures/bar_chart_set_b.pdf}
        \caption{Track M: Motion Continuity}
    \end{subfigure}
    \caption{Grouped Bar Charts of Model Performance. In \textbf{Track S}, models must achieve high scores across all metrics. In \textbf{Track M}, we plot inverted axes for Diversity and Sharpness ($1-x$) such that higher bars consistently represent better performance across all scenarios.}
    \label{fig:bar_chart}
\end{figure*}

\begin{table*}[t!]
\centering
\caption{Main Results on \textbf{Track S (Semantic Leap)} and \textbf{Track M (Motion Continuity)}. Track S demands narrative-driven dynamics ($\uparrow$ is better for all). Track M demands spatial stability ($\downarrow$ is better for Diversity and Sharpness). Best in \textbf{bold}.}
\label{tab:main_results}
\resizebox{0.95\textwidth}{!}{
\begin{tabular}{ll|cccc|cccc}
\toprule
& & \multicolumn{4}{c|}{\textbf{Track S (Semantic Leap)}} & \multicolumn{4}{c}{\textbf{Track M (Motion Continuity)}} \\
\textbf{Category} & \textbf{Method} & \textbf{Cons.} $\uparrow$ & \textbf{Div.} $\uparrow$ & \textbf{DSA} $\uparrow$ & \textbf{Sharp.} $\uparrow$ & \textbf{Cons.} $\uparrow$ & \textbf{Div.} $\downarrow$ & \textbf{DSA} $\uparrow$ & \textbf{Sharp.} $\downarrow$ \\
\midrule
Foundation & CogVideoX~\cite{yang2024cogvideox} & 0.902 & 0.073 & 0.045 & 0.262 & \textbf{0.939} & \textbf{0.046} & 0.020 & 0.227 \\
Foundation & LTX-Video~\cite{HaCohen2024LTXVideo} & \textbf{0.951} & 0.037 & 0.024 & 0.132 & 0.885 & 0.086 & 0.010 & 0.296 \\
Foundation & ModelScope & 0.851 & 0.112 & 0.031 & 0.352 & 0.822 & 0.134 & 0.014 & 0.385 \\
Foundation & SVD~\cite{blattmann2023stable} & 0.816 & 0.138 & 0.020 & 0.102 & 0.852 & 0.111 & 0.012 & \textbf{0.064} \\
Framework & AnimateDiff~\cite{guo2023animatediff} & 0.816 & 0.138 & 0.023 & 0.485 & 0.765 & 0.176 & 0.017 & 0.530 \\
Framework & FreeNoise~\cite{qiu2023freenoise} & 0.528 & 0.354 & 0.032 & \textbf{0.893} & 0.565 & 0.326 & 0.020 & 0.808 \\
Framework & StoryDiffusion~\cite{zhou2024storydiffusion} & 0.443 & \textbf{0.418} & \textbf{0.222} & 0.702 & 0.377 & 0.467 & \textbf{0.060} & 0.710 \\
Framework & Mora~\cite{yuan2024mora} & 0.412 & 0.385 & 0.185 & 0.654 & 0.352 & 0.412 & 0.045 & 0.685 \\
Framework & ShotAdapter & 0.385 & 0.362 & 0.164 & 0.612 & 0.321 & 0.385 & 0.038 & 0.652 \\
\bottomrule
\end{tabular}}
\end{table*}

\subsection{Group 1: Foundation T2V Models and the Static Trap}
Foundation models (e.g., CogVideoX, LTX-Video, SVD) exhibit the raw limits of monolithic spatiotemporal priors. They achieve high Subject Consistency ($>0.80$) but catastrophically low Background Diversity ($<0.10$) in Track S. More importantly, their \textbf{DSA} scores remain near zero, proving they generate a single static scene regardless of narrative instructions. This results in a uniform probability distribution in the DSA heatmaps (Fig.~\ref{fig:dsa_heatmaps}(A)), indicating a total failure to isolate instructions.

\subsection{Group 2: T2MSV Frameworks and Identity Amnesia}
Specialized frameworks successfully break out of the Static Trap, achieving higher Background Diversity and DSA scores in Track S. However, this dynamism comes at the cost of identity preservation. Their Subject Consistency plummets, a phenomenon we define as \textbf{Identity Amnesia}. As visualized in our performance landscape in Fig.~\ref{fig:scatter}, these models prioritize dynamics but fail to maintain a coherent subject across shots.

\subsection{The ``Double-Kill'' Pareto Frontier}
Our comprehensive analysis uncovers a fundamental \textbf{``Double-Kill'' dilemma}: current architectures either preserve identity at the expense of dynamics (the Static Trap) or prioritize dynamics but suffer from severe Identity Amnesia. As shown in the scatter plot in Fig.~\ref{fig:scatter}, models are clustered in either the top-left or bottom-right quadrants, leaving the top-right \textbf{``Unoccupied Ideal Zone''} completely empty. This Pareto frontier suggests a structural entanglement in current video priors that prevents simultaneous spatiotemporal control.

\subsection{The Context Paradox}
Our dual-track evaluation exposes the \textbf{Context Paradox}: a model's metric performance can be misleading without contextualizing the scenario. For instance, CogVideoX exhibits exceptionally low Background Diversity. In Track M, this might be misidentified as excellent spatial stability. However, the same model exhibits the same low diversity in Track S, proving it is merely trapped in static generation. This cross-scenario diagnosis is essential for distinguishing intentional continuity from generative failure.

\begin{figure*}[t!]
    \centering
    \includegraphics[width=\linewidth]{figures/rich_tradeoff_scatter.pdf}
    \caption{The comprehensive performance landscape across Track S and Track M. The plots explicitly show the relationship between Subject Consistency, Background Diversity, and our proposed Diagonal Semantic Alignment (DSA). Current models are completely missing from the ``Ideal Decoupled'' goal (high consistency, high DSA).}
    \label{fig:scatter}
\end{figure*}
