\section{Experiments and Unveiling the Blind Spots}
\label{sec:experiments}

Our evaluation on Dynamic-MSV-Bench reveals a systematic failure in current video generation architectures. To properly diagnose these failures, we categorized the evaluated baselines into two distinct groups: \textbf{Group 1: Foundation T2V Models} and \textbf{Group 2: Specialized T2MSV Frameworks}.

\begin{figure*}[ht]
    \centering
    \begin{subfigure}{0.48\linewidth}
        \includegraphics[width=\linewidth]{figures/radar_chart_set_a.pdf}
        \caption{Track S: Semantic Leap}
    \end{subfigure}\hfill
    \begin{subfigure}{0.48\linewidth}
        \includegraphics[width=\linewidth]{figures/radar_chart_set_b.pdf}
        \caption{Track M: Motion Continuity}
    \end{subfigure}
    \caption{Radar Charts of Model Performance. In \textbf{Track S}, an ideal model would form a large diamond. In \textbf{Track M}, we plot inverted axes for Diversity and Sharpness ($1-x$) such that a large area consistently represents high performance. Current models fail to achieve the target horizontal "bowtie" geometry in Track M due to near-zero instruction adherence.}
    \label{fig:radar}
\end{figure*}

\subsection{Group 1: Foundation T2V Models and the Static Trap}
Foundation models (e.g., CogVideoX, LTX-Video, SVD) exhibit the raw limits of spatiotemporal priors. They achieve high Subject Consistency (>0.80) but catastrophically low Background Diversity (<0.10) in Track S. Their upgraded \textbf{DSA} scores remain near $0.02$, proving they generate a single static scene regardless of narrative instructions. This results in the uniform probability distribution seen in Fig.~\ref{fig:dsa_heatmaps}(A).

\subsection{Group 2: T2MSV Frameworks and the Trade-off Dilemma}
Specialized frameworks like StoryDiffusion successfully break out of the Static Trap, achieving higher Background Diversity in Track S. However, this dynamism comes at the severe cost of identity preservation. Their Subject Consistency plummets, leading to \textit{Identity Amnesia}, visualized by the Pareto frontier in Figure~\ref{fig:scatter}. 

\begin{figure}[ht]
    \centering
    \includegraphics[width=\linewidth]{figures/tradeoff_scatter.pdf}
    \caption{The Identity-Dynamics Pareto Frontier: \textbf{Track S} (Circles) vs. \textbf{Track M} (Crosses). Connecting lines represent the shift of individual models between the two stress-test tracks. The ideal top-right goal remains unoccupied, as models either collapse into the Static Trap (top-left) or suffer from Identity Amnesia/Hallucination (bottom-right). Dot size represents DSA score.}
    \label{fig:scatter}
\end{figure}

\subsection{The "Double-Kill" and the Context Paradox}
Our evaluation exposes a fascinating paradox: a metric's value is deeply context-dependent. As visualized by the connecting lines in Figure~\ref{fig:scatter}, models exhibit a significant "migration" between failure modes. For instance, CogVideoX exhibits exceptionally low Background Diversity in both tracks. In Track M, traditional evaluators might misinterpret this as excellent spatial continuity. However, our dual-track analysis reveals the truth: the same model's low diversity in Track S proves it is merely trapped in static generation. 

Conversely, StoryDiffusion shows a "dynamics-at-all-costs" behavior; while it achieves some narrative shift in Track S, it fails to "calm down" in Track M, leading to unwanted background hallucination. This multi-track migration confirms that achieving high-quality T2MSV requires \textbf{Decoupled Dynamics}â€”the ability to selectively engage or disengage motion priors while strictly preserving identity.

\begin{figure}[ht]
    \centering
    \includegraphics[width=\linewidth]{figures/fig4_filmstrip.pdf}
    \caption{Qualitative comparison on Track M. The "Static Trap" (Top Row) mimics continuity through total lack of motion (DSA $\approx 0$). Specialized frameworks (Bottom Row) attempt motion but ignore the specific "Panning" vs. "Zooming" instructions (Low DSA). Both current paradigms fail to execute controlled multi-shot motion.}
    \label{fig:qualitative}
\end{figure}

\begin{table*}[t]
\centering
\caption{Main Results on Track S (Semantic Leap). (Golden Rule: All metrics should be $\uparrow$. Best in \textbf{bold}.)}
\label{tab:main_results_track_s}
\resizebox{\textwidth}{!}{
\begin{tabular}{ll|cccc}
\toprule
\textbf{Category} & \textbf{Method} & \textbf{Subj. Cons.} $\uparrow$ & \textbf{BG Div.} $\uparrow$ & \textbf{DSA} $\uparrow$ & \textbf{Sharpness} $\uparrow$ \\
\midrule
Framework & AnimateDiff & 0.816 & 0.138 & 0.023 & 0.485 \\
Foundation & CogVideoX & 0.902 & 0.073 & 0.045 & 0.262 \\
Framework & FreeNoise & 0.528 & 0.354 & 0.032 & \textbf{0.893} \\
Foundation & LTX-Video & \textbf{0.951} & 0.037 & 0.024 & 0.132 \\
Foundation & ModelScope & 0.851 & 0.112 & 0.031 & 0.352 \\
Foundation & SVD & 0.816 & 0.138 & 0.020 & 0.102 \\
Framework & StoryDiffusion & 0.443 & \textbf{0.418} & \textbf{0.222} & 0.702 \\
\bottomrule
\end{tabular}}
\end{table*}

\begin{table*}[t]
\centering
\caption{Main Results on Track M (Motion Continuity). (Golden Rule: Cons. $\uparrow$, Div. $\downarrow$, DSA $\uparrow$, Sharpness $\downarrow$. Best in \textbf{bold}.)}
\label{tab:main_results_track_m}
\resizebox{\textwidth}{!}{
\begin{tabular}{ll|cccc}
\toprule
\textbf{Category} & \textbf{Method} & \textbf{Subj. Cons.} $\uparrow$ & \textbf{BG Div.} $\downarrow$ & \textbf{DSA} $\uparrow$ & \textbf{Sharpness} $\downarrow$ \\
\midrule
Framework & AnimateDiff & 0.765 & 0.176 & 0.017 & 0.530 \\
Foundation & CogVideoX & \textbf{0.939} & \textbf{0.046} & 0.020 & 0.227 \\
Framework & FreeNoise & 0.565 & 0.326 & 0.020 & 0.808 \\
Foundation & LTX-Video & 0.885 & 0.086 & 0.010 & 0.296 \\
Foundation & ModelScope & 0.822 & 0.134 & 0.014 & 0.385 \\
Foundation & SVD & 0.852 & 0.111 & 0.012 & \textbf{0.064} \\
Framework & StoryDiffusion & 0.377 & 0.467 & \textbf{0.060} & 0.710 \\
\bottomrule
\end{tabular}}
\end{table*}
