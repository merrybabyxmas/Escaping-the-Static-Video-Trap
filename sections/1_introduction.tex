\section{Introduction}
\label{sec:intro}

The field of generative video AI is rapidly transitioning from synthesizing blurry, single-shot clips to attempting complex, cinematic multi-shot narratives, a paradigm shift we define as \textbf{Text-to-Multi-Shot Video (T2MSV)}. This evolution promises to revolutionize digital storytelling, enabling the creation of coherent films and dynamic visual narratives from simple textual sequences. However, as the complexity of the generated content increases, our ability to evaluate it has stagnated. Current evaluation methodologies remain deeply anchored in a single-shot mindset, relying on metrics that fail to account for the unique spatiotemporal challenges of multi-shot synthesis.

Existing quality and consistency metrics, such as Fréchet Video Distance (FVD)~\cite{blattmann2023stable} or frame-wise CLIP similarity~\cite{radford2021learning}, evaluate generated videos holistically. In the context of T2MSV, this holistic approach introduces a critical structural vulnerability: it inadvertently rewards generative models that produce entirely static, unchanging videos, even when those models are explicitly prompted to execute highly dynamic scene transitions. We define this pervasive failure phenomenon as the \textbf{Static Video Trap}. For example, if a model is prompted with a sequence demanding a narrative leap—such as jumping from a ``dense rainforest'' to ``deep outer space''—a model that stubbornly generates a continuous rainforest scene will score artificially high on traditional temporal consistency metrics. This creates the \textbf{Global Similarity Paradox}, where conventional metrics inherently reward the failure to transition, thereby masking a fundamental inability to follow complex shot-level semantic instructions.

\begin{figure*}[t]
    \centering
    \resizebox{\textwidth}{!}{%
    \begin{tikzpicture}[
        font=\sffamily\small,
        box/.style={draw, rounded corners, inner sep=10pt, thick},
        sectionbox/.style={box, fill=black!2, minimum width=17.5cm, align=left},
        imgnode/.style={inner sep=0pt, draw=black, thick},
        arrow/.style={->, >=latex, thick, draw=black!70}
    ]

    % --- SECTION A: Problem Exposure ---
    \node[sectionbox, minimum height=4.5cm] (secA) at (0, 0) {};
    \node[anchor=north west, font=\bfseries\large] at (secA.north west) {A. Failure Modes in Multi-Shot Video Generation (Track S: Space Traveler)};

    % Prompts
    \node[anchor=north west, align=left, text width=5cm, inner sep=5pt] (prompts) at ([xshift=0.5cm, yshift=-1cm]secA.north west) {
        \textbf{Input Prompts:}\\[3pt]
        \textit{Shot 1:} ``A mysterious space traveler standing in an \textbf{underwater city}...''\\[3pt]
        \textit{Shot 2:} ``...standing in a \textbf{martian surface}...''
    };

    % Static Trap Case
    \node[anchor=north west, align=center] (cx1) at ([xshift=6cm, yshift=-0.8cm]secA.north west) {\includegraphics[width=2.5cm, height=2.5cm, keepaspectratio]{figures/cx_shot1.png}\\[2pt]Shot 1 (Underwater)};
    \node[anchor=west, align=center] (cx2) at ([xshift=0.2cm]cx1.east) {\includegraphics[width=2.5cm, height=2.5cm, keepaspectratio]{figures/cx_shot2.png}\\[2pt]Shot 2 (Failed Leap)};
    
    \node[anchor=south, align=center, text=red!80!black, font=\bfseries] (cxlabel) at ([yshift=-0.2cm, xshift=1.35cm]cx1.south) {Failure 1: Static Trap\\(High Continuity, Ignores Prompt)};
    \draw[arrow, dashed, red!80!black] (cx1.east) -- (cx2.west);

    % Identity Amnesia Case
    \node[anchor=west, align=center] (sd1) at ([xshift=1.5cm]cx2.east) {\includegraphics[width=2.5cm, height=2.5cm, keepaspectratio]{figures/sd_shot1.png}\\[2pt]Shot 1 (Subject A)};
    \node[anchor=west, align=center] (sd2) at ([xshift=0.2cm]sd1.east) {\includegraphics[width=2.5cm, height=2.5cm, keepaspectratio]{figures/sd_shot2.png}\\[2pt]Shot 2 (Morphed B)};
    
    \node[anchor=south, align=center, text=orange!90!black, font=\bfseries] (sdlabel) at ([yshift=-0.2cm, xshift=1.35cm]sd1.south) {Failure 2: Identity Amnesia\\(Background Shifts, Subject Melts)};
    \draw[arrow, dashed, orange!90!black] (sd1.east) -- (sd2.west);


    % --- SECTION B: Pipeline ---
    \node[sectionbox, minimum height=3.5cm] (secB) at ([yshift=-5.0cm]secA.center) {};
    \node[anchor=north west, font=\bfseries\large] at (secB.north west) {B. The DIAL Pipeline \& Diagonal Semantic Alignment (DSA)};

    % Matrix M
    \node[anchor=north west, align=center] (matM) at ([xshift=1cm, yshift=-0.8cm]secB.north west) {
        \textbf{Absolute Similarity Matrix $M$}\\
        $\begin{bmatrix} 0.85 & 0.40 \\ 0.30 & 0.75 \end{bmatrix}$
    };

    % Equation
    \node[anchor=west, align=center, draw, fill=white, rounded corners, inner sep=5pt] (eq) at ([xshift=2cm]matM.east) {
        \textbf{Column-wise Softmax Normalization}\\[5pt]
        $P_{i,j} = \frac{\exp(\tau \cdot M_{i,j})}{\sum_{k=1}^{K} \exp(\tau \cdot M_{k,j})}$
    };

    % Matrix P
    \node[anchor=west, align=center] (matP) at ([xshift=2cm]eq.east) {
        \textbf{DSA Heatmap $P$ (Contrastive)}\\
        $\begin{bmatrix} \mathbf{0.95} & 0.05 \\ 0.05 & \mathbf{0.95} \end{bmatrix}$
    };
    \node[below=5pt of matP, text=green!60!black, font=\bfseries] {Forces Instruction Isolation ($DSA \rightarrow 1$)};

    \draw[arrow] (matM.east) -- (eq.west);
    \draw[arrow] (eq.east) -- (matP.west);


    % --- SECTION C: Results ---
    \node[sectionbox, minimum height=4.5cm] (secC) at ([yshift=-4.5cm]secB.center) {};
    \node[anchor=north west, font=\bfseries\large] at (secC.north west) {C. Unveiling the ``Double-Kill'' Dilemma};

    % Legacy vs DIAL text
    \node[anchor=north west, align=left, text width=6cm] (textC) at ([xshift=1cm, yshift=-1cm]secC.north west) {
        \textbf{Legacy Metrics (e.g., FVD)}\\
        Inherently reward uniform continuity, giving ``Static Trap'' models passing scores.\\[5pt]
        \textbf{DIAL Metrics}\\
        Orthogonally evaluates Diversity and Consistency, mathematically assigning $0.0$ to static generation.
    };

    % Scatter Plot
    \begin{scope}[shift={(9, -13.5)}]
        \begin{axis}[
            width=7cm, height=4cm,
            xlabel={Background Diversity $\rightarrow$},
            ylabel={Subject Consistency $\uparrow$},
            xmin=-0.05, xmax=1.05,
            ymin=-0.05, ymax=1.05,
            xtick={0, 1}, ytick={0, 1},
            grid=both, grid style={dashed, gray!30},
            axis background/.style={fill=white},
            legend pos=south west,
            legend style={nodes={scale=0.7, transform shape}, font=\sffamily}
        ]
        
        \addplot[only marks, mark=*, mark size=4pt, red!70, fill=red!40] coordinates {(0.1, 0.9) (0.15, 0.85)};
        \node[red!80!black, font=\bfseries] at (axis cs:0.25,0.7) {Static Trap};
        
        \addplot[only marks, mark=*, mark size=4pt, orange!70, fill=orange!40] coordinates {(0.85, 0.2) (0.9, 0.3)};
        \node[orange!90!black, font=\bfseries] at (axis cs:0.75,0.4) {Amnesia};
        
        \addplot[only marks, mark=star, mark size=6pt, green!60!black, fill=green!40!black] coordinates {(0.95, 0.95)};
        \node[green!60!black, font=\bfseries] at (axis cs:0.65,0.95) {Ideal Zone (Empty)};
        
        \end{axis}
    \end{scope}

    \end{tikzpicture}
    }
    \caption{Overview of the \textbf{DIAL} Benchmark and the \textbf{DSA} Pipeline. \textbf{(A)} We utilize actual generated frames from our stress-test scenarios (e.g., Track S) to demonstrate how current models exploit traditional metrics via the \textbf{Static Trap} or fail visually via \textbf{Identity Amnesia}. \textbf{(B)} Our \textbf{Diagonal Semantic Alignment (DSA)} leverages a column-wise softmax to mathematically guarantee instruction isolation and explicitly penalize context bleeding. \textbf{(C)} This rigorous formulation successfully uncovers the underlying ``Double-Kill'' structural dilemma, proving that current architectures fail to balance spatiotemporal dynamics.}
    \label{fig:overview}
\end{figure*}

Furthermore, current evaluation paradigms are blind to \textbf{Context Bleeding}, where semantic elements from one prompt erroneously persist into subsequent shots. This failure is often obscured by the use of absolute CLIP scores, which measure overall alignment but fail to quantify the \textit{isolation} of instructions. Ironically, we observe that naive baselines—such as concatenating independently generated shots—can achieve higher text alignment scores than sophisticated end-to-end models, a paradox that further underscores the need for a contrastive evaluation framework. When models do attempt to escape the Static Trap by executing dynamic transitions, they frequently succumb to \textbf{Identity Amnesia}, wherein the model loses the fine-grained visual features of the main subject across shots. This suggests a fundamental \textbf{``Double-Kill'' dilemma} in current monolithic architectures: they can either preserve identity at the expense of dynamics or prioritize dynamics at the expense of identity, but they struggle to achieve both.

In this work, we argue that T2MSV requires more than mere alignment; it demands \textbf{Temporal Instruction Isolation}—the ability to execute a specific prompt exclusively at a specific time while actively rejecting adjacent contextual noise. To address this, we introduce \textbf{DIAL} (Diagonal Instruction ALignment), a comprehensive evaluation benchmark designed to diagnose these exact capabilities through a 4D decoupled evaluation framework. Our benchmark categorizes evaluation into two orthogonal tracks: \textbf{Track S (Semantic Leap)} tests narrative diversity by requiring radical environment changes while strictly preserving the subject, and \textbf{Track M (Motion Continuity)} evaluates spatial integrity, where the background must remain consistent while the camera executes specific physical motions.

To quantitatively support this taxonomy, we propose a 4D decoupled evaluation pipeline assessing subject identity, background dynamics, cut sharpness, and instruction alignment. Central to this pipeline is \textbf{Diagonal Semantic Alignment (DSA)}, a novel metric that applies column-wise softmax normalization to shot-prompt similarity matrices. This formulation forces a zero-sum game, demanding exclusivity and penalizing context bleeding, while mathematically guaranteeing a zero score for static, instruction-ignoring videos.

Our core contributions are summarized as follows:
\begin{itemize}
    \item We systematize the critical failure modes of T2MSV: the \textbf{Static Trap}, \textbf{Context Bleeding}, and \textbf{Identity Amnesia}, highlighting how legacy metrics inadvertently reward these failures.
    \item We propose \textbf{DIAL}, a benchmark featuring 1,000 stress-test scenarios, alongside a 4D decoupled evaluation pipeline.
    \item We introduce \textbf{Diagonal Semantic Alignment (DSA)}, a mathematically rigorous metric that utilizes contrastive normalization to penalize context bleeding and ensure a zero score for static generation.
    \item We conduct an exhaustive evaluation of 9 state-of-the-art models, uncovering the \textbf{``Double-Kill'' Pareto frontier} and establishing a diagnostic foundation for next-generation decoupled video priors.
\end{itemize}